# Adding New Languages

This guide explains how to add support for new Indian languages to the Fake News Detection Bot.

## Current Supported Languages

- English (en)
- Tamil (ta)

## Steps to Add a New Language

### 1. Install Language Support

#### For Tesseract OCR

```bash
# Example: Adding Hindi support
sudo apt-get install tesseract-ocr-hin

# Example: Adding Telugu support
sudo apt-get install tesseract-ocr-tel

# Example: Adding Kannada support
sudo apt-get install tesseract-ocr-kan

# Example: Adding Malayalam support
sudo apt-get install tesseract-ocr-mal
```

List of Tesseract language codes:
- Hindi: `hin`
- Telugu: `tel`
- Kannada: `kan`
- Malayalam: `mal`
- Marathi: `mar`
- Bengali: `ben`
- Gujarati: `guj`
- Punjabi: `pan`

#### Update .env Configuration

```env
TESSERACT_LANGS=eng+tam+hin+tel
```

### 2. Add Response Templates

Edit `backend/utils/response_generator.py`:

```python
# Add your language to the templates dictionary
'hi': {  # Hindi
    'false': {
        'emoji': 'üî¥',
        'title': '‡§ù‡•Ç‡§†',
        'verdict_text': '‡§Ø‡§π ‡§¶‡§æ‡§µ‡§æ ‡§ú‡§æ‡§Å‡§ö‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§î‡§∞ ‡§ù‡•Ç‡§†‡§æ ‡§™‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§',
        'advice': '‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§∏ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§∏‡§æ‡§ù‡§æ ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§'
    },
    'misleading': {
        'emoji': 'üü°',
        'title': '‡§≠‡•ç‡§∞‡§æ‡§Æ‡§ï',
        'verdict_text': '‡§Ø‡§π ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§≠‡•ç‡§∞‡§æ‡§Æ‡§ï ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§ö‡§ø‡§π‡•ç‡§®‡§ø‡§§ ‡§ï‡•Ä ‡§ó‡§à ‡§π‡•à‡•§',
        'advice': '‡§õ‡§µ‡§ø ‡§Ø‡§æ ‡§¶‡§æ‡§µ‡•á ‡§ï‡•ã ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§'
    },
    'unverified': {
        'emoji': '‚ö™',
        'title': '‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡•á',
        'verdict_text': '‡§π‡§Æ ‡§Ö‡§™‡§®‡•á ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§¶‡§æ‡§µ‡•á ‡§ï‡•ã ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡•á‡•§',
        'advice': '‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§æ‡§µ‡§ß‡§æ‡§® ‡§∞‡§π‡•á‡§Ç ‡§î‡§∞ ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§ï‡§à ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∏‡•ç‡§∞‡•ã‡§§‡•ã‡§Ç ‡§∏‡•á ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§'
    },
    'true': {
        'emoji': 'üü¢',
        'title': '‡§∏‡§ö',
        'verdict_text': '‡§Ø‡§π ‡§¶‡§æ‡§µ‡§æ ‡§∏‡§ö ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§',
        'advice': '‡§Ø‡§π ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§∏‡§ü‡•Ä‡§ï ‡§™‡•ç‡§∞‡§§‡•Ä‡§§ ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§'
    },
    'greeting': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞, ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§î‡§∞ ‡§≤‡§ø‡§Ç‡§ï ‡§ï‡•ã ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç‡•§',
    'processing': '‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç... ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç‡•§',
    'error': '‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Ü‡§™‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§ï‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•Å‡§à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®: ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§',
    'source_prefix': '\n\nüìå ‡§∏‡•ç‡§∞‡•ã‡§§: ',
    'explanation_prefix': '\n\nüí° ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ:\n',
    'original_context': '\n\nüîç ‡§Æ‡•Ç‡§≤ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠:\n'
}
```

### 3. Update Language Detection

The `langdetect` library automatically detects most Indian languages. Verify the language code mapping in `backend/analyzers/text_analyzer.py`:

```python
lang_map = {
    'en': 'en',
    'ta': 'ta',
    'hi': 'hi',  # Hindi
    'te': 'te',  # Telugu
    'ml': 'ml',  # Malayalam
    'kn': 'kn',  # Kannada
    'mr': 'mr',  # Marathi
    'bn': 'bn',  # Bengali
    'gu': 'gu',  # Gujarati
    'pa': 'pa',  # Punjabi
}
```

### 4. Update Supported Languages Configuration

In `.env`:

```env
SUPPORTED_LANGUAGES=en,ta,hi,te,kn,ml
DEFAULT_LANGUAGE=en
```

### 5. Add NLP Support (Optional)

For better text analysis in your language:

#### Install SpaCy Language Model

```bash
# For multilingual support (already included)
python -m spacy download xx_ent_wiki_sm

# For specific languages (if available)
python -m spacy download hi_core_news_sm  # Hindi (if available)
```

### 6. Update Database

Add language-specific fact-checks to the database:

```python
from backend.models.database import FactCheck
from backend.database.setup_db import db

session = db.get_session()

fact_check = FactCheck(
    claim='Your claim in the new language',
    verdict='false',
    explanation='Explanation in the new language',
    source='source_name',
    source_url='https://example.com',
    language='hi',  # Language code
    keywords=[],
    embedding=[]
)

session.add(fact_check)
session.commit()
```

### 7. Test the New Language

Create a test script:

```python
from backend.utils.response_generator import response_generator

# Test the new language responses
response = response_generator.get_verdict_response(
    verdict='false',
    language='hi',  # Your language code
    explanation='‡§Ø‡§π ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ ‡§π‡•à',
    confidence_score=0.9
)

print(response)
```

## Example: Complete Hindi Integration

Here's a complete example for adding Hindi:

### 1. Install Tesseract

```bash
sudo apt-get install tesseract-ocr-hin
```

### 2. Update .env

```env
TESSERACT_LANGS=eng+tam+hin
SUPPORTED_LANGUAGES=en,ta,hi
```

### 3. Add Hindi Templates

See the code example in step 2 above.

### 4. Test

```python
# Test text analysis
from backend.analyzers.text_analyzer import text_analyzer

text = "‡§Ø‡§π ‡§è‡§ï ‡§ù‡•Ç‡§†‡•Ä ‡§ñ‡§¨‡§∞ ‡§π‡•à"
result = text_analyzer.analyze_text(text)
print(f"Detected language: {result['language']}")

# Test response
from backend.utils.response_generator import response_generator

response = response_generator.get_verdict_response(
    verdict='false',
    language='hi',
    explanation='‡§Ø‡§π ‡§¶‡§æ‡§µ‡§æ ‡§ó‡§≤‡§§ ‡§π‡•à'
)
print(response)
```

## Translation Resources

For accurate translations of technical terms:

### Common Terms

| English | Hindi | Tamil | Telugu | Kannada | Malayalam |
|---------|-------|-------|---------|---------|-----------|
| False | ‡§ù‡•Ç‡§† | ‡Æ™‡Øä‡ÆØ‡Øç | ‡∞Ö‡∞¨‡∞¶‡±ç‡∞ß‡∞Ç | ‡≤∏‡≥Å‡≤≥‡≥ç‡≤≥‡≥Å | ‡¥ï‡¥≥‡µç‡¥≥‡¥Ç |
| Misleading | ‡§≠‡•ç‡§∞‡§æ‡§Æ‡§ï | ‡Æ§‡Æµ‡Æ±‡Ææ‡Æ© | ‡∞§‡∞™‡±ç‡∞™‡±Å‡∞¶‡±ã‡∞µ ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞Ç‡∞ö‡±á | ‡≤§‡≤™‡≥ç‡≤™‡≥Å ‡≤¶‡≤æ‡≤∞‡≤ø ‡≤π‡≤ø‡≤°‡≤ø‡≤∏‡≥Å‡≤µ | ‡¥§‡µÜ‡¥±‡µç‡¥±‡¥ø‡¥¶‡µç‡¥ß‡¥∞‡¥ø‡¥™‡µç‡¥™‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥® |
| Cannot Verify | ‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡•á | ‡Æö‡Æ∞‡Æø‡Æ™‡Ææ‡Æ∞‡Øç‡Æï‡Øç‡Æï ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡Æµ‡Æø‡Æ≤‡Øç‡Æ≤‡Øà | ‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞≤‡±á‡∞Æ‡±Å | ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤≤‡≥Å ‡≤∏‡≤æ‡≤ß‡≥ç‡≤Ø‡≤µ‡≤ø‡≤≤‡≥ç‡≤≤ | ‡¥™‡¥∞‡¥ø‡¥∂‡µã‡¥ß‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥ï‡¥¥‡¥ø‡¥Ø‡¥ø‡¥≤‡µç‡¥≤ |
| True | ‡§∏‡§ö | ‡Æâ‡Æ£‡Øç‡ÆÆ‡Øà | ‡∞®‡∞ø‡∞ú‡∞Ç | ‡≤®‡≤ø‡≤ú | ‡¥∏‡¥§‡µç‡¥Ø‡¥Ç |
| Source | ‡§∏‡•ç‡§∞‡•ã‡§§ | ‡ÆÜ‡Æ§‡Ææ‡Æ∞‡ÆÆ‡Øç | ‡∞Æ‡±Ç‡∞≤‡∞Ç | ‡≤Æ‡≥Ç‡≤≤ | ‡¥∏‡µç‡¥∞‡µã‡¥§‡¥∏‡µç‡¥∏‡µç |

## Language-Specific Scrapers

To add scrapers for fact-checkers in your language:

```python
class HindiFactCheckerScraper(BaseScraper):
    """Scraper for Hindi fact-checking website."""
    
    def __init__(self):
        base_url = 'https://hindi-factchecker.com'
        super().__init__('Hindi Fact Checker', base_url)
    
    def scrape_article(self, url):
        # Implement scraping logic
        # Make sure to set language='hi' in the returned dict
        return {
            'claim': 'Claim in Hindi',
            'verdict': 'false',
            'explanation': 'Explanation in Hindi',
            'source': 'hindi_checker',
            'source_url': url,
            'language': 'hi'  # Important!
        }
```

## Testing Multilingual Support

Run comprehensive tests:

```bash
# Test all components with new language
python test_system.py

# Test via API
curl -X POST http://localhost:5000/analyze/text \
  -H "Content-Type: application/json" \
  -d '{"text": "‡§Ø‡§π ‡§è‡§ï ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§π‡•à", "language": "hi"}'
```

## Community Contributions

When adding a new language:

1. Update this documentation
2. Add test cases
3. Provide sample data in the new language
4. Submit a pull request with:
   - Language code
   - Response templates
   - Sample fact-checks
   - Updated documentation

## Resources

- Tesseract Language Data: https://github.com/tesseract-ocr/tessdata
- SpaCy Models: https://spacy.io/models
- langdetect: https://pypi.org/project/langdetect/
- Google Translate API (for translations): https://cloud.google.com/translate

## Need Help?

If you need help adding a new language:
1. Open an issue on GitHub
2. Provide sample text in your language
3. Share any language-specific fact-checking resources
4. Join our community discussions
